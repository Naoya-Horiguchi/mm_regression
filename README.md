HOWTO
=====

## prerequisite
- make kernel source available via /src/linux-dev
- install gcc, ruby, and numactl in your test system

## note
- This test tool contains many page migration testcases, most of which are
  meaningful only on NUMA system. so please run this on NUMA system.

## Recipe list
- This testsuite is recipe based, which means that you can choose the set of
  testcases to be run by specifying file paths of relevant recipe files.
- Some testcases are similar, so they can be defined in recipe set file
  (files with extension .set under cases/.)
- You can create real testcase recipes by running command 'make split_recipes'
  or 'make update_recipes'.
- The list of (runnnable) recipes are generated by command 'make allrecipes'

## run test
- If you want to run a testcase defined in a recipe file cases/foo, you run
  the following command:
```
RECIPEFILES=cases/foo make test
```

- You can give multiple recipes like:
```
RECIPEFILES="cases/foo cases/bar" make test
```
- RECIPEFILES is handled as a file pathname, so you can use '*'
```
RECIPEFILES="cases/foo*" make test
```

- 'make allrecipes' combined with grep gives you very easy/powerful filtering:
```
RECIPEFILES="$(make allrecipes | grep foo)" make test
```

- There're some other useful options/environment variables:
  - RUNNAME: you can give ID for each run, which is mainly useful to separate
    result directory. Test results are store under work/$RUNNAME. If RUNNAME
    is not given, timestamp ("date +%y%m%d_%H%M%S" form) is used.
  - AGAIN: in order to make automation easier, if you run the test with RUNNAME
    with which you already run other testcases, "already finished" testcases
    are skipped. To cancel this behavior and overwrite existing result, give
    some non-empty string to this variable. Note that existing test results
    are removed.
  - SOFT_RETRY: some testcase has a characteristic that the test occationally
    fails for a good reason (for example page migration.) IOW, one failure
    doesn't mean the teescase's failure. If you set SOFT_RETRY, one success
    in SOFT_RETRY trials is considered as testcase success.
  - HARD_RETRY: contrary to SOFT_RETRY, if some testcase needs to succeed
    multiple times to be considered as testcase success, you can set this
    variable.
  - HIGHEST_PRIORITY (Default 0): some testcases are not appropriate to be
    run in your regular testing for various reasons (the testcase under
    developing, obsolete, and/or known to cause kernel panic ...).
    If you set PRORITY= in your testcase recipe, and run with
    HIGHEST_PRIORITY (>= PRIORITY), the testcases is skipped in the current
    run. In priority value, lower value is highest priority (0 is highest.)
    Default value of PRIORITY (given to every testcase) is 10.
  - LOWEST_PRIORITY (Default 10): similar to HIGHEST_PRIORITY. If you want
    to run the testcase with lower priority (higher PRIORITY value,) give
    some larger value to LOWEST_PRIORITY.

## result
- Test result are stored under work/$RUNNAME. The results of each testcase
  is saved under work/$RUNNAME/$RECIPEID.
- A test summary script is available:
```
    [build7:~/mm_regression]$ ruby test_core/lib/test_summary.rb work/debug
    /root/mm_regression/work/debug
    PASS 112, FAIL 7, NONE 0, SKIP 10, WARN 1
    checkcount 477, checkpass 410, checkfail 44, checklater 23
```

## Contact
- Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
